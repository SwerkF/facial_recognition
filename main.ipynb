{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a0b8c6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14856753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks \n",
    " \n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6),\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    TensorBoard(log_dir='./logs', histogram_freq=1, write_graph=True),\n",
    "    ModelCheckpoint(filepath='model.keras', save_best_only=True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7b804c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données d'entraienement \n",
    "\n",
    "def load_data():\n",
    "    # Initialiser les listes pour les données et les labels\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    test_data = []\n",
    "    test_labels = []\n",
    "\n",
    "    # Données oliwer et damien\n",
    "\n",
    "    # for photos in ['oliwer', 'damien']: \n",
    "    for photos in ['oliwer']:\n",
    "        train = f'processed/{photos}/train/' # Images d'entraînement\n",
    "\n",
    "        for file in os.listdir(train):\n",
    "            if file.endswith('.jpg') or file.endswith('.png'):\n",
    "                img = os.path.join(train, file) # Lire le chemin de l'image\n",
    "                image = cv2.imread(img, cv2.IMREAD_GRAYSCALE) # Transformer l'image en gris\n",
    "                train_data.append(image) # Ajouter l'image à la liste des données d'entraînement\n",
    "                train_labels.append(photos) # Ajouter le label correspondant\n",
    "\n",
    "        for file in os.listdir(f'processed/{photos}/test/'):\n",
    "            if file.endswith('.jpg') or file.endswith('.png'):\n",
    "                img = os.path.join(f'processed/{photos}/test/', file) # Lire le chemin de l'image de test\n",
    "                image = cv2.imread(img, cv2.IMREAD_GRAYSCALE) # Transformer l'image en gris\n",
    "                test_data.append(image) # Ajouter l'image à la liste des données de test\n",
    "                test_labels.append(photos) # Ajouter le label correspondant\n",
    "\n",
    "    # Données aléatoires\n",
    "\n",
    "    random_images = []\n",
    "    random_dir = './lfw-deepfunneled/lfw-deepfunneled'  # Dossier avec des images aléatoires\n",
    "    \n",
    "    for person in os.listdir(random_dir):\n",
    "        person_path = os.path.join(random_dir, person) # Chemin du sous-dossier de la personne\n",
    "        if os.path.isdir(person_path):\n",
    "            for filename in os.listdir(person_path):\n",
    "                img_path = os.path.join(person_path, filename) # Chemin complet de l'image\n",
    "                if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "                    image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE) # Transformer l'image en gris\n",
    "                    image = cv2.resize(image, (128, 128)) # Redimensionner l'image à 128x128 pixels\n",
    "                    random_images.append(image) # Ajouter l'image à la liste des images aléatoires\n",
    "\n",
    "    # Sélectionner 80 images pour l'entraînement et 20 pour le test\n",
    "    np.random.shuffle(random_images)\n",
    "    train_data.extend(random_images[:80])\n",
    "    train_labels.extend(['random'] * 80)\n",
    "    test_data.extend(random_images[80:100])\n",
    "    test_labels.extend(['random'] * 20)\n",
    "\n",
    "    return np.array(train_data), np.array(train_labels), np.array(test_data), np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b21b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des données \n",
    "\n",
    "train_data, train_labels, test_data, test_labels = load_data() # Charger les données\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels = label_encoder.fit_transform(train_labels)  # Encoder les labels d'entraînement\n",
    "test_labels = label_encoder.transform(test_labels)        # Encoder les labels de test\n",
    "\n",
    "train_labels = to_categorical(train_labels, num_classes=3)  # Convertir les labels en categorical\n",
    "test_labels = to_categorical(test_labels, num_classes=3)\n",
    "\n",
    "train_data = train_data.reshape(-1, 128, 128, 1)  # Reshape pour le modèle CNN\n",
    "test_data = test_data.reshape(-1, 128, 128, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
