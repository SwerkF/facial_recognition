#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script de correction et debug pour le modÃ¨le de reconnaissance faciale
ProblÃ¨me: Le modÃ¨le prÃ©dit toujours 0 mÃªme pour les images USER

Author: GitHub Copilot
Date: 2025-07-31
"""

import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt

class FacialRecognitionDebugger:
    def __init__(self, model_path="./models/best_model_damien.h5"):
        self.model_path = model_path
        self.model = None
        self.image_size = (128, 128)
        self.selected_user = "damien"
        
        # Charger le modÃ¨le
        self.load_model()
    
    def load_model(self):
        """Charge le modÃ¨le sauvegardÃ©"""
        if os.path.exists(self.model_path):
            try:
                self.model = tf.keras.models.load_model(self.model_path)
                print(f"âœ… ModÃ¨le chargÃ©: {self.model_path}")
                return True
            except Exception as e:
                print(f"âŒ Erreur chargement modÃ¨le: {e}")
                return False
        else:
            print(f"âŒ ModÃ¨le non trouvÃ©: {self.model_path}")
            return False
    
    def preprocess_image(self, image_path):
        """PrÃ©processe une image"""
        try:
            # Charger l'image
            img = tf.keras.preprocessing.image.load_img(image_path, target_size=self.image_size)
            
            # Convertir en array
            img_array = tf.keras.preprocessing.image.img_to_array(img)
            
            # Normaliser les pixels (0-1) - CRITIQUE
            img_array = img_array / 255.0
            
            # Ajouter dimension batch
            img_array = np.expand_dims(img_array, axis=0)
            
            return img_array
        except Exception as e:
            print(f"âŒ Erreur preprocessing: {e}")
            return None
    
    def analyze_image_stats(self, image_path):
        """Analyse les statistiques d'une image"""
        print(f"\nğŸ” ANALYSE: {os.path.basename(image_path)}")
        print("-" * 50)
        
        # Image originale
        img_orig = tf.keras.preprocessing.image.load_img(image_path, target_size=self.image_size)
        img_orig_array = tf.keras.preprocessing.image.img_to_array(img_orig)
        
        print(f"ğŸ“Š Image originale:")
        print(f"   Shape: {img_orig_array.shape}")
        print(f"   Min: {img_orig_array.min():.1f}")
        print(f"   Max: {img_orig_array.max():.1f}")
        print(f"   Mean: {img_orig_array.mean():.1f}")
        
        # Image prÃ©processÃ©e
        img_processed = self.preprocess_image(image_path)
        if img_processed is not None:
            print(f"ğŸ“Š Image prÃ©processÃ©e:")
            print(f"   Shape: {img_processed.shape}")
            print(f"   Min: {img_processed.min():.3f}")
            print(f"   Max: {img_processed.max():.3f}")
            print(f"   Mean: {img_processed.mean():.3f}")
            
            return img_processed
        return None
    
    def predict_with_debug(self, image_path):
        """PrÃ©diction avec debug complet"""
        if self.model is None:
            print("âŒ Aucun modÃ¨le chargÃ©")
            return None
        
        # Analyser l'image
        img_array = self.analyze_image_stats(image_path)
        if img_array is None:
            return None
        
        # PrÃ©diction brute
        raw_prediction = self.model.predict(img_array, verbose=0)[0][0]
        
        print(f"\nğŸ¯ PRÃ‰DICTION:")
        print(f"   Brute: {raw_prediction:.6f}")
        print(f"   Type: {type(raw_prediction)}")
        
        # Analyser la distribution des activations
        self.analyze_model_layers(img_array)
        
        return raw_prediction
    
    def analyze_model_layers(self, img_array):
        """Analyse les activations des couches du modÃ¨le"""
        print(f"\nğŸ§  ANALYSE DES COUCHES:")
        
        try:
            # Analyser couche par couche
            x = img_array
            for i, layer in enumerate(self.model.layers[:8]):  # Analyser les premiÃ¨res couches
                if hasattr(layer, '__call__'):
                    x = layer(x)
                    layer_name = layer.name
                    print(f"   Couche {i} ({layer_name}):")
                    print(f"     Shape: {x.shape}")
                    print(f"     Min: {x.numpy().min():.4f}")
                    print(f"     Max: {x.numpy().max():.4f}")
                    print(f"     Mean: {x.numpy().mean():.4f}")
                    
                    # DÃ©tecter les problÃ¨mes
                    if x.numpy().max() == 0:
                        print(f"     âš ï¸  PROBLÃˆME: Toutes les valeurs sont 0!")
                        break
                    if np.isnan(x.numpy()).any():
                        print(f"     âš ï¸  PROBLÃˆME: Valeurs NaN dÃ©tectÃ©es!")
                        break
                        
        except Exception as e:
            print(f"   âŒ Erreur analyse couches: {e}")
            
            # Analyse simple de la sortie finale
            print(f"   ğŸ“Š Analyse de la sortie finale seulement:")
    
    def test_dataset_labels(self):
        """VÃ©rifie les labels du dataset d'entraÃ®nement"""
        print(f"\nğŸ“‹ VÃ‰RIFICATION DES LABELS:")
        
        # Charger le dataset
        try:
            train_ds = tf.keras.preprocessing.image_dataset_from_directory(
                './binary_dataset',
                validation_split=0.2,
                subset='training',
                seed=1,
                label_mode='binary',
                batch_size=32,
                image_size=self.image_size
            )
            
            class_names = train_ds.class_names
            print(f"   Classes: {class_names}")
            
            # VÃ©rifier l'ordre des classes
            if class_names[0] == 'others' and class_names[1] == 'user':
                print("   âœ… Labels corrects: others=0, user=1")
                return False  # Pas d'inversion
            elif class_names[0] == 'user' and class_names[1] == 'others':
                print("   âš ï¸  Labels inversÃ©s: user=0, others=1")
                print("   ğŸ’¡ Le modÃ¨le a Ã©tÃ© entraÃ®nÃ© avec les labels inversÃ©s!")
                return True  # Inversion dÃ©tectÃ©e
            else:
                print(f"   â“ Ordre de classes inattendu: {class_names}")
                return None
                
        except Exception as e:
            print(f"   âŒ Erreur chargement dataset: {e}")
            return None
    
    def correct_prediction(self, raw_prediction, is_inverted=None):
        """Corrige la prÃ©diction si les labels sont inversÃ©s"""
        if is_inverted is None:
            is_inverted = self.test_dataset_labels()
        
        if is_inverted:
            corrected = 1.0 - raw_prediction
            print(f"ğŸ”„ Correction appliquÃ©e: {raw_prediction:.3f} â†’ {corrected:.3f}")
            return corrected
        else:
            return raw_prediction
    
    def test_multiple_user_images(self):
        """Teste plusieurs images du dossier user"""
        user_dir = './binary_dataset/user'
        
        if not os.path.exists(user_dir):
            print(f"âŒ Dossier non trouvÃ©: {user_dir}")
            return
        
        user_images = [f for f in os.listdir(user_dir) 
                      if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        
        if not user_images:
            print("âŒ Aucune image dans le dossier user")
            return
        
        print(f"\nğŸ§ª TEST DE {len(user_images)} IMAGES USER:")
        print("=" * 60)
        
        # VÃ©rifier les labels une seule fois
        labels_inverted = self.test_dataset_labels()
        
        for i, img_file in enumerate(user_images[:5]):  # Limiter Ã  5 images
            img_path = os.path.join(user_dir, img_file)
            print(f"\n{i+1}. {img_file}")
            
            # PrÃ©diction brute
            raw_pred = self.predict_with_debug(img_path)
            
            if raw_pred is not None:
                # Correction si nÃ©cessaire
                corrected_pred = self.correct_prediction(raw_pred, labels_inverted)
                
                # DÃ©cision
                is_user = corrected_pred >= 0.5
                status = "âœ… DAMIEN DETECTE" if is_user else "âŒ AUTRE PERSONNE"
                
                print(f"ğŸ¯ RÃ©sultat final: {status}")
                print(f"ğŸ“Š ProbabilitÃ©: {corrected_pred:.3f}")
                print(f"ğŸ’ª Confiance: {max(corrected_pred, 1-corrected_pred):.1%}")
    
    def diagnose_zero_predictions(self):
        """Diagnostique spÃ©cifique pour les prÃ©dictions nulles"""
        print(f"\nğŸ” DIAGNOSTIC PRÃ‰DICTIONS NULLES:")
        print("=" * 50)
        
        # Tester plusieurs images
        user_dir = './binary_dataset/user'
        others_dir = './binary_dataset/others'
        
        test_results = {'user': [], 'others': []}
        
        # Tester images USER
        if os.path.exists(user_dir):
            user_images = [f for f in os.listdir(user_dir) 
                          if f.lower().endswith(('.jpg', '.jpeg', '.png'))][:3]
            
            print("ğŸ“Š Test images USER:")
            for img_file in user_images:
                img_path = os.path.join(user_dir, img_file)
                img_array = self.preprocess_image(img_path)
                if img_array is not None:
                    pred = self.model.predict(img_array, verbose=0)[0][0]
                    test_results['user'].append(pred)
                    print(f"   {img_file}: {pred:.6f}")
        
        # Tester images OTHERS
        if os.path.exists(others_dir):
            others_images = [f for f in os.listdir(others_dir) 
                            if f.lower().endswith(('.jpg', '.jpeg', '.png'))][:3]
            
            print("ğŸ“Š Test images OTHERS:")
            for img_file in others_images:
                img_path = os.path.join(others_dir, img_file)
                img_array = self.preprocess_image(img_path)
                if img_array is not None:
                    pred = self.model.predict(img_array, verbose=0)[0][0]
                    test_results['others'].append(pred)
                    print(f"   {img_file}: {pred:.6f}")
        
        # Analyser les rÃ©sultats
        print(f"\nğŸ“ˆ ANALYSE DES RÃ‰SULTATS:")
        if test_results['user']:
            user_preds = np.array(test_results['user'])
            print(f"   USER - Min: {user_preds.min():.6f}, Max: {user_preds.max():.6f}, Mean: {user_preds.mean():.6f}")
        
        if test_results['others']:
            others_preds = np.array(test_results['others'])
            print(f"   OTHERS - Min: {others_preds.min():.6f}, Max: {others_preds.max():.6f}, Mean: {others_preds.mean():.6f}")
        
        # Diagnostic
        all_preds = test_results['user'] + test_results['others']
        if all_preds:
            if all(pred < 0.001 for pred in all_preds):
                print(f"\nâŒ PROBLÃˆME IDENTIFIÃ‰: Toutes les prÃ©dictions sont quasi-nulles!")
                print(f"ğŸ’¡ Causes possibles:")
                print(f"   1. ModÃ¨le mal entraÃ®nÃ© ou corrompu")
                print(f"   2. ProblÃ¨me de normalisation des donnÃ©es")
                print(f"   3. Gradients qui disparaissent")
                print(f"   4. ProblÃ¨me d'architecture du modÃ¨le")
                return "all_zero"
            elif all(pred > 0.999 for pred in all_preds):
                print(f"\nâŒ PROBLÃˆME: Toutes les prÃ©dictions sont quasi-maximales!")
                return "all_one"
            else:
                print(f"\nâœ… Les prÃ©dictions semblent normales")
                return "normal"
        
        return "no_data"
    
    def suggest_solutions(self, problem_type):
        """SuggÃ¨re des solutions selon le type de problÃ¨me"""
        print(f"\nğŸ’¡ SOLUTIONS SUGGÃ‰RÃ‰ES:")
        
        if problem_type == "all_zero":
            print(f"ğŸ”§ Solution 1: VÃ©rifier la normalisation")
            print(f"   - Les images doivent Ãªtre normalisÃ©es entre 0 et 1")
            print(f"   - Diviser par 255.0, pas par 255")
            
            print(f"\nğŸ”§ Solution 2: RÃ©entraÃ®ner le modÃ¨le")
            print(f"   - Le modÃ¨le actuel semble dÃ©faillant")
            print(f"   - Utiliser un learning rate plus Ã©levÃ©")
            
            print(f"\nğŸ”§ Solution 3: VÃ©rifier l'architecture")
            print(f"   - Couche de sortie: Dense(1, activation='sigmoid')")
            print(f"   - Loss: 'binary_crossentropy'")
            
        elif problem_type == "all_one":
            print(f"ğŸ”§ Le modÃ¨le prÃ©dit toujours 1 - vÃ©rifier les labels")
            
        elif problem_type == "normal":
            print(f"âœ… Le modÃ¨le fonctionne correctement")
            
        else:
            print(f"â“ Pas assez de donnÃ©es pour diagnostiquer")

    def quick_fix_test(self, image_path):
        """Test rapide avec correction automatique"""
        print(f"\nğŸš€ TEST RAPIDE: {os.path.basename(image_path)}")
        
        if not os.path.exists(image_path):
            print(f"âŒ Image non trouvÃ©e: {image_path}")
            return None
        
        # VÃ©rifier les labels
        labels_inverted = self.test_dataset_labels()
        
        # PrÃ©diction
        img_array = self.preprocess_image(image_path)
        if img_array is None:
            return None
        
        raw_pred = self.model.predict(img_array, verbose=0)[0][0]
        corrected_pred = self.correct_prediction(raw_pred, labels_inverted)
        
        # RÃ©sultat
        is_user = corrected_pred >= 0.5
        status = "âœ… DAMIEN DETECTE" if is_user else "âŒ AUTRE PERSONNE"
        
        print(f"ğŸ¯ {status}")
        print(f"ğŸ“Š ProbabilitÃ©: {corrected_pred:.3f}")
        
        return {
            'raw': raw_pred,
            'corrected': corrected_pred,
            'is_user': is_user,
            'status': status
        }

def main():
    """Fonction principale de debug"""
    print("ğŸ”§ DEBUGGER DE RECONNAISSANCE FACIALE")
    print("=" * 50)
    
    # Initialiser le debugger
    debugger = FacialRecognitionDebugger()
    
    if debugger.model is None:
        print("âŒ Impossible de charger le modÃ¨le. ArrÃªt.")
        return
    
    print(f"âœ… Debugger initialisÃ© pour {debugger.selected_user}")
    
    # Diagnostic spÃ©cifique pour les prÃ©dictions nulles
    problem_type = debugger.diagnose_zero_predictions()
    debugger.suggest_solutions(problem_type)
    
    # Test d'une image spÃ©cifique pour analyse dÃ©taillÃ©e
    user_dir = "./binary_dataset/user"
    if os.path.exists(user_dir):
        user_images = [f for f in os.listdir(user_dir) 
                      if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        if user_images:
            test_path = os.path.join(user_dir, user_images[0])
            print(f"\n" + "=" * 50)
            print("ğŸ¯ ANALYSE DÃ‰TAILLÃ‰E D'UNE IMAGE:")
            debugger.predict_with_debug(test_path)
    
    # Instructions pour l'utilisateur
    print(f"\n" + "=" * 50)
    print("ğŸ“ INSTRUCTIONS POUR CORRIGER:")
    print("1. Le modÃ¨le actuel semble dÃ©faillant")
    print("2. Recommandation: RÃ©entraÃ®ner le modÃ¨le")
    print("3. VÃ©rifier la normalisation des donnÃ©es (diviser par 255.0)")
    print("4. Utiliser un learning rate plus Ã©levÃ© (ex: 0.001)")
    print("5. VÃ©rifier que la loss est 'binary_crossentropy'")

if __name__ == "__main__":
    main()